{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VoiceDub - YouTube Dubbing Backend (GPU)\n",
    "\n",
    "This notebook runs the dubbing backend on Google Colab's free T4 GPU.\n",
    "\n",
    "**Setup:**\n",
    "1. Go to **Runtime > Change runtime type > T4 GPU**\n",
    "2. Run all cells below\n",
    "3. Copy the `ngrok` public URL and paste it in your frontend\n",
    "\n",
    "**Features:** Chatterbox TTS (human-like voice) + Whisper (GPU transcription) + Gemini translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 1. Check GPU\n",
    "!nvidia-smi\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 2. Clone repo & install dependencies\nimport os\nif os.path.exists('/content/app'):\n    !cd /content/app && git pull\nelse:\n    !git clone https://github.com/sasmalgiri/youtube-dubbing.git /content/app\n%cd /content/app/backend\n\n# Install build tools needed by chatterbox-tts\n!apt-get -qq install -y libsndfile1 > /dev/null 2>&1\n!pip install -q Cython numpy\n\n# Install backend requirements\n!pip install -q -r requirements.txt\n\n# Install ngrok for public URL tunnel\n!pip install -q pyngrok\n\nprint(\"\\nAll dependencies installed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 3. Set API Keys\n#@markdown Enter your API keys below:\n\nGEMINI_API_KEY = \"\" #@param {type:\"string\"}\nELEVENLABS_API_KEY = \"\" #@param {type:\"string\"}\nOPENAI_API_KEY = \"\" #@param {type:\"string\"}\nNGROK_AUTH_TOKEN = \"\" #@param {type:\"string\"}\nNGROK_DOMAIN = \"\" #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown **Required:** `GEMINI_API_KEY` (free at https://aistudio.google.com/apikey)\n#@markdown\n#@markdown **Required:** `NGROK_AUTH_TOKEN` (free at https://dashboard.ngrok.com/get-started/your-authtoken)\n#@markdown\n#@markdown **Optional:** `NGROK_DOMAIN` â€” your free static domain from ngrok dashboard (e.g. `your-name.ngrok-free.dev`)\n#@markdown\n#@markdown **Optional:** `ELEVENLABS_API_KEY`, `OPENAI_API_KEY`\n\nimport os\nos.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\nif ELEVENLABS_API_KEY:\n    os.environ['ELEVENLABS_API_KEY'] = ELEVENLABS_API_KEY\nif OPENAI_API_KEY:\n    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n\n# Write .env file\nwith open('/content/app/backend/.env', 'w') as f:\n    f.write(f'GEMINI_API_KEY={GEMINI_API_KEY}\\n')\n    if ELEVENLABS_API_KEY:\n        f.write(f'ELEVENLABS_API_KEY={ELEVENLABS_API_KEY}\\n')\n    if OPENAI_API_KEY:\n        f.write(f'OPENAI_API_KEY={OPENAI_API_KEY}\\n')\n\nprint(\"API keys set!\")\nprint(f\"  Gemini: {'configured' if GEMINI_API_KEY else 'MISSING'}\")\nprint(f\"  ElevenLabs: {'configured' if ELEVENLABS_API_KEY else 'not set (optional)'}\")\nprint(f\"  OpenAI: {'configured' if OPENAI_API_KEY else 'not set (optional)'}\")\nprint(f\"  ngrok: {'configured' if NGROK_AUTH_TOKEN else 'MISSING'}\")\nprint(f\"  ngrok domain: {NGROK_DOMAIN or 'not set (will use random URL)'}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 4. Pre-download Whisper model (faster first job)\n",
    "from faster_whisper import WhisperModel\n",
    "print(\"Downloading Whisper 'small' model...\")\n",
    "model = WhisperModel(\"small\", device=\"cuda\", compute_type=\"float16\")\n",
    "del model\n",
    "print(\"Whisper model cached!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title 5. Start Backend Server + ngrok Tunnel\n#@markdown This cell starts the FastAPI backend and creates a public URL.\n\nimport subprocess\nimport time\nfrom pyngrok import ngrok, conf\n\n# Set ngrok auth token\nif NGROK_AUTH_TOKEN:\n    conf.get_default().auth_token = NGROK_AUTH_TOKEN\nelse:\n    print(\"ERROR: ngrok auth token is required!\")\n    print(\"Get one free at: https://dashboard.ngrok.com/get-started/your-authtoken\")\n    raise ValueError(\"Missing NGROK_AUTH_TOKEN\")\n\n# Start uvicorn in background\nproc = subprocess.Popen(\n    ['python', '-m', 'uvicorn', 'app:app', '--host', '0.0.0.0', '--port', '8000'],\n    cwd='/content/app/backend',\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n)\ntime.sleep(3)\n\n# Use static domain if provided, otherwise get a random URL\nif NGROK_DOMAIN:\n    public_url = ngrok.connect(8000, \"http\", domain=NGROK_DOMAIN)\n    url = f\"https://{NGROK_DOMAIN}\"\nelse:\n    public_url = ngrok.connect(8000, \"http\")\n    url = str(public_url)\n\nprint(\"=\" * 60)\nprint(\"Backend running on GPU!\")\nprint(\"\")\nprint(f\"PUBLIC URL: {url}\")\nprint(\"\")\nprint(\"To connect your local frontend:\")\nprint(f\"  1. Create web/.env.local with:\")\nprint(f\"     NEXT_PUBLIC_API_URL={url}\")\nprint(f\"  2. Restart frontend: npm run dev\")\nprint(\"\")\nprint(f\"Test: {url}/api/health\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 6. Monitor Server Logs (run this to see live output)\n",
    "#@markdown Keep this cell running to see backend logs in real-time.\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"Monitoring server... (this cell keeps running)\")\n",
    "print(\"Submit a dubbing job from your frontend to see progress here.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "try:\n",
    "    while proc.poll() is None:\n",
    "        line = proc.stdout.readline()\n",
    "        if line:\n",
    "            print(line.decode('utf-8', errors='replace').rstrip())\n",
    "        else:\n",
    "            time.sleep(0.5)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopped monitoring (server still running)\")"
   ]
  }
 ]
}