{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# VoiceDub - YouTube Dubbing Backend (GPU)\n\nThis notebook runs the dubbing backend on Google Colab's free T4 GPU.\n\n**Setup:**\n1. Go to **Runtime > Change runtime type > T4 GPU**\n2. Run **Cell 1** (install) — this will restart the runtime\n3. After restart, **skip Cell 1** and run Cells 2, 3, 4 in order\n\n**Features:** Chatterbox TTS (human-like voice) + Whisper (GPU transcription) + Groq/Gemini translation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "#@title 1. Install Dependencies (run ONCE, restarts runtime)\n#@markdown Run this cell first. It installs everything and restarts the runtime.\n#@markdown **After restart, skip this cell and go to Cell 2.**\n\nimport os\n\n# Clone or update repo\nif os.path.exists('/content/app'):\n    !cd /content/app && git fetch origin && git reset --hard origin/master\nelse:\n    !git clone https://github.com/sasmalgiri/youtube-dubbing.git /content/app\n\n# Install build tools\n!apt-get -qq install -y libsndfile1 > /dev/null 2>&1\n\n# Fix numpy for chatterbox (must be 1.26.x)\n!pip install -q numpy==1.26.4\n\n# Install chatterbox deps manually (pip build fails on Colab)\n!pip install -q \"librosa>=0.11.0\" \"s3tokenizer\" \"torch>=2.6.0\" \"torchaudio>=2.6.0\" \\\n    \"transformers==4.46.3\" \"diffusers==0.29.0\" \"resemble-perth>=1.0.1\" \\\n    \"conformer>=0.3.2\" \"safetensors>=0.5.3\" \"spacy-pkuseg\" \"pykakasi>=2.3.0\" \\\n    \"pyloudnorm\" \"omegaconf\"\n!pip install -q chatterbox-tts --no-deps\n\n# Install backend deps + pyngrok\n!pip install -q fastapi uvicorn[standard] python-multipart pydantic edge-tts \\\n    faster-whisper deep-translator google-genai groq openai elevenlabs \\\n    sse-starlette rich yt-dlp pyngrok\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"All installed! Restarting runtime for numpy fix...\")\nprint(\"After restart, SKIP this cell and run Cells 2, 3, 4.\")\nprint(\"=\" * 60)\nos._exit(0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "#@title 2. Set API Keys + Setup\n#@markdown Enter your API keys and run this cell.\n\nGROQ_API_KEY = \"\" #@param {type:\"string\"}\nGEMINI_API_KEY = \"\" #@param {type:\"string\"}\nELEVENLABS_API_KEY = \"\" #@param {type:\"string\"}\nOPENAI_API_KEY = \"\" #@param {type:\"string\"}\nNGROK_AUTH_TOKEN = \"\" #@param {type:\"string\"}\nNGROK_DOMAIN = \"\" #@param {type:\"string\"}\n\n#@markdown ---\n#@markdown **Required:** `NGROK_AUTH_TOKEN` + at least one translation key (`GROQ_API_KEY` recommended)\n#@markdown\n#@markdown **Translation priority:** OpenAI GPT-4o > Groq Llama 3.3 > Gemini > Google Translate\n#@markdown\n#@markdown **Optional:** `NGROK_DOMAIN`, `ELEVENLABS_API_KEY`, `OPENAI_API_KEY`\n\nimport os\n\n# Set environment variables\nif GROQ_API_KEY:\n    os.environ['GROQ_API_KEY'] = GROQ_API_KEY\nif GEMINI_API_KEY:\n    os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\nif ELEVENLABS_API_KEY:\n    os.environ['ELEVENLABS_API_KEY'] = ELEVENLABS_API_KEY\nif OPENAI_API_KEY:\n    os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n\n# Ensure repo + backend dir exist\nif not os.path.exists('/content/app/backend'):\n    !git clone https://github.com/sasmalgiri/youtube-dubbing.git /content/app\n\n# Write .env file\nos.makedirs('/content/app/backend', exist_ok=True)\nwith open('/content/app/backend/.env', 'w') as f:\n    if GROQ_API_KEY:\n        f.write(f'GROQ_API_KEY={GROQ_API_KEY}\\n')\n    if GEMINI_API_KEY:\n        f.write(f'GEMINI_API_KEY={GEMINI_API_KEY}\\n')\n    if ELEVENLABS_API_KEY:\n        f.write(f'ELEVENLABS_API_KEY={ELEVENLABS_API_KEY}\\n')\n    if OPENAI_API_KEY:\n        f.write(f'OPENAI_API_KEY={OPENAI_API_KEY}\\n')\n\n# Install deno for yt-dlp (in case YouTube URL is used directly)\n!curl -fsSL https://deno.land/install.sh | sh 2>/dev/null\nos.environ['PATH'] = '/root/.deno/bin:' + os.environ.get('PATH', '')\n\n# Check GPU and pre-download Whisper model\nimport torch\nprint(f\"\\nGPU available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    device, compute = 'cuda', 'float16'\nelse:\n    print(\"WARNING: No GPU detected! Go to Runtime > Change runtime type > T4 GPU\")\n    print(\"Continuing with CPU (slower transcription, no Chatterbox)...\")\n    device, compute = 'cpu', 'int8'\n\nprint(\"\\nPre-downloading Whisper model...\")\n%cd /content/app/backend\nfrom faster_whisper import WhisperModel\nmodel = WhisperModel('small', device=device, compute_type=compute)\ndel model\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Setup complete!\")\nprint(f\"  GPU:        {'YES - ' + torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'NO (CPU mode)'}\")\nprint(f\"  Groq:       {'configured (recommended)' if GROQ_API_KEY else 'not set'}\")\nprint(f\"  Gemini:     {'configured' if GEMINI_API_KEY else 'not set'}\")\nprint(f\"  OpenAI:     {'configured' if OPENAI_API_KEY else 'not set (optional)'}\")\nprint(f\"  ElevenLabs: {'configured' if ELEVENLABS_API_KEY else 'not set (optional)'}\")\nprint(f\"  ngrok:      {'configured' if NGROK_AUTH_TOKEN else 'MISSING'}\")\nprint(f\"  ngrok domain: {NGROK_DOMAIN or 'not set (will use random)'}\")\ntranslation = \"OpenAI\" if OPENAI_API_KEY else \"Groq\" if GROQ_API_KEY else \"Gemini\" if GEMINI_API_KEY else \"Google Translate (basic)\"\nprint(f\"\\n  Translation engine: {translation}\")\nprint(\"=\" * 60)\nprint(\"\\nNow run Cell 3 to start the server!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 3. Start Backend Server + ngrok Tunnel\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "# Ensure deno is in PATH\n",
    "os.environ['PATH'] = '/root/.deno/bin:' + os.environ.get('PATH', '')\n",
    "\n",
    "# Set ngrok auth token\n",
    "if not NGROK_AUTH_TOKEN:\n",
    "    raise ValueError('Missing NGROK_AUTH_TOKEN — go back to Cell 2')\n",
    "conf.get_default().auth_token = NGROK_AUTH_TOKEN\n",
    "\n",
    "# Start uvicorn in background\n",
    "proc = subprocess.Popen(\n",
    "    ['python', '-m', 'uvicorn', 'app:app', '--host', '0.0.0.0', '--port', '8000'],\n",
    "    cwd='/content/app/backend',\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT,\n",
    "    env=os.environ.copy(),\n",
    ")\n",
    "time.sleep(3)\n",
    "\n",
    "# Connect ngrok\n",
    "if NGROK_DOMAIN:\n",
    "    public_url = ngrok.connect(8000, 'http', domain=NGROK_DOMAIN)\n",
    "    url = f'https://{NGROK_DOMAIN}'\n",
    "else:\n",
    "    public_url = ngrok.connect(8000, 'http')\n",
    "    url = str(public_url)\n",
    "\n",
    "print('=' * 60)\n",
    "print('Backend running on GPU!')\n",
    "print(f'\\nPUBLIC URL: {url}')\n",
    "print(f'\\nTest: {url}/api/health')\n",
    "print('\\nSet this in your frontend .env.local:')\n",
    "print(f'  NEXT_PUBLIC_API_URL={url}')\n",
    "print('=' * 60)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#@title 4. Monitor Server Logs\n",
    "#@markdown Keep this cell running to see backend logs in real-time.\n",
    "\n",
    "import time\n",
    "\n",
    "print('Monitoring server... (this cell keeps running)')\n",
    "print('Submit a dubbing job from your frontend to see progress here.')\n",
    "print('-' * 60)\n",
    "\n",
    "try:\n",
    "    while proc.poll() is None:\n",
    "        line = proc.stdout.readline()\n",
    "        if line:\n",
    "            print(line.decode('utf-8', errors='replace').rstrip())\n",
    "        else:\n",
    "            time.sleep(0.5)\n",
    "    print('\\nServer process exited!')\n",
    "except KeyboardInterrupt:\n",
    "    print('\\nStopped monitoring (server still running)')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}